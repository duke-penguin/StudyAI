{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【ラビットチャレンジ】深層学習後編（day3,day4）\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1.再起型ニューラルネットワークの概念\n",
    " \n",
    "時系列データに対応できるニューラルネットワーク\n",
    "\n",
    "系列データとは？時間的順序を追って一定間隔ごとに観察され，しかも相互に統計的依存関係が認められるようなデータの系列\n",
    "* 音声データ\n",
    "* テキストデータ\n",
    "\n",
    "<img src=\"RNN_1.jpg\">\n",
    "左図を展開したものが、右となる。\n",
    "\n",
    "中間層への入力は、前回の中間層の状態 $ Z_{(t-1)} $ からの入力と新たな入力 $ X_t $ が加えられたものとなる。\n",
    "\n",
    "計算式は以下の通り\n",
    "\n",
    " \n",
    " \n",
    " $$\n",
    " u^t = W_{(in)} x^t + W z^{t-1} + b\n",
    " $$\n",
    " \n",
    " $$\n",
    " z^t = f(W_{(in)}x^t + W z^{t-1}+b)\n",
    " $$\n",
    " \n",
    " $$\n",
    " v^t = W_{(out)}z^t + c\n",
    " $$\n",
    " \n",
    " $$\n",
    " y^t = g(W_{(out)}z^t+c)\n",
    " $$\n",
    "\n",
    "計算には、\n",
    "* 入力から現在の中間層を定義する際の重み $ W_{(in)} $, \n",
    "* 中間層から出力を定義する際の重み $ W_{(out)} $\n",
    "* 中間層の前の状態から中間層を定義する際の重み $ W $ \n",
    "\n",
    "#### 確認テスト\n",
    "の3つの重みがある\n",
    "* 入力から現在の中間層を定義する際の重み $ W_{(in)} $, \n",
    "* 中間層から出力を定義する際の重み $ W_{(out)} $\n",
    "* 中間層の前の状態から中間層を定義する際の重み $ W $ \n",
    "\n",
    "\n",
    "#### 実装演習\n",
    "\n",
    "<b>順伝搬</b>\n",
    "\n",
    "スライド S1)1-3\n",
    "$$\n",
    "u^t = \\mathbf{W}_{in} x^t + \\mathbf{W} z^{(t+1)} + b \\\\\n",
    "z^t = f( \\mathbf{W}_{in} x^t + \\mathbf{W} z^{(t+1)} + b) \\\\\n",
    "v^t = \\mathbf{W}_{out} z^t + c \\\\\n",
    "y^t = g(\\mathbf{W}_{out} z^t + c)\n",
    "$$\n",
    "\n",
    "対応するコード。\n",
    " <code>\n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    " </code>\n",
    " \n",
    " ### BPTT (Back Propagation Through Time)\n",
    " \n",
    "\n",
    "RNN における逆伝搬の計算式は以下のようになる。\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial W_{(in)}}=\\frac{\\partial E}{\\partial u^t}\\left[\\frac{\\partial u^t}{\\partial W_{(in)}}\\right]^T=\\delta^t[x^t]^T \\\\\n",
    "\\frac{\\partial E}{\\partial W_{(out)}}=\\frac{\\partial E}{\\partial v^t}\\left[\\frac{\\partial v^t}{\\partial W_{(out)}}\\right]^T=\\delta^{out,t}[z^t]^T \\\\\n",
    "\\frac{\\partial E}{\\partial W}=\\frac{\\partial E}{\\partial u^t}\\left[\\frac{\\partial u^t}{\\partial W}\\right]^T=\\delta^t[z^{t-1}]^T \\\\\n",
    "\\frac{\\partial E}{\\partial b}=\\frac{\\partial E}{\\partial u^t}\\frac{\\partial u^t}{\\partial b} = \\delta^t \\\\\n",
    "\\frac{\\partial E}{\\partial c}=\\frac{\\partial E}{\\partial v^t}\\frac{\\partial v^t}{\\partial c} = \\delta^{out,t}\n",
    "$$\n",
    "\n",
    "重み W が3種類あるので、W に関する微分が3式、bに関する微分が 1 つ、cに関する式が1つ。\n",
    "\n",
    "\n",
    "$ \\delta^t $ は $ {\\partial E \\over \\partial u} $、$ \\delta^{out,t} $ は $ {\\partial E \\over \\partial v} $を表す。\n",
    "\n",
    "\n",
    "パラメータ更新式\n",
    "\n",
    "$$\n",
    "W^{t+1}_{(in)}=W^{t}_{(in)}-\\epsilon\\frac{\\partial E}{\\partial W_{(in)}}=W^t_{(in)}-\\epsilon\\sum_{z=0}^{T_t}\\delta^{t-z}[x^{t-z}]^T\n",
    "$$\n",
    "$$\n",
    "W^{t+1}_{(out)}=W^{t}_{(out)}-\\epsilon\\frac{\\partial E}{\\partial W_{(in)}}=W^t_{(out)}-\\epsilon\\delta^{out,t}[z^{t}]^T\n",
    "$$\n",
    "$$\n",
    "W^{t+1}=W^{t}-\\epsilon\\frac{\\partial E}{\\partial W}=W^t_{(in)}-\\epsilon\\sum_{z=0}^{T_t}\\delta^{t-z}[z^{t-z-1}]^T,\\\\\n",
    "$$\n",
    "$$\n",
    "b^{t+1}=b^t−\\epsilon \\frac{\\partial E}{\\partial b}=b^t−\\epsilon  \\sum_{z=0}^{T_t} \\delta^{t−z}\n",
    "$$\n",
    "$$\n",
    "c^{t+1}=c^t−\\epsilon\\frac{\\partial E}{\\partial c} =c^t−\\epsilon \\delta^{out,t}\n",
    "$$\n",
    "\n",
    "#### 確認テスト\n",
    "$$\n",
    "y_1 = g(W_{out} s_1 + c) \\\\\n",
    "s_1 = f(w_{in} x_1 + w s_0 + b )\n",
    "$$\n",
    "\n",
    "\n",
    "#### 実装演習　3_1_simple_RNN\n",
    "\n",
    "<b>逆伝搬</b>\n",
    "\n",
    "スライド S1)2-2\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial W_{(in)}}=\\frac{\\partial E}{\\partial u^t}\\left[\\frac{\\partial u^t}{\\partial W_{(in)}}\\right]^T=\\delta^t[x^t]^T \\\\\n",
    "\\frac{\\partial E}{\\partial W_{(out)}}=\\frac{\\partial E}{\\partial v^t}\\left[\\frac{\\partial v^t}{\\partial W_{(out)}}\\right]^T=\\delta^{out,t}[z^t]^T \\\\\n",
    "\\frac{\\partial E}{\\partial W}=\\frac{\\partial E}{\\partial u^t}\\left[\\frac{\\partial u^t}{\\partial W}\\right]^T=\\delta^t[z^{t-1}]^T\n",
    "$$\n",
    "\n",
    "対応するコード\n",
    "<code>\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.LSTM(Long-short term model)\n",
    "\n",
    "RNN の問題点。\n",
    "活性化関数の微分により、勾配消失問題が発生する。\n",
    "\n",
    "\n",
    "<img src=\"LSTM_1.png\">\n",
    "\n",
    "この図がわかりにくかったので、別の図を探した。\n",
    "\n",
    "<img src=\"LSTM_2.jpg\">\n",
    "$$\n",
    "f^{(t)} = f^\\sigma_f(x^{(t)},h^{(t-1)}) \\\\\n",
    "i^{(t)} = f^\\sigma_i(x^{(t)},h^{(t-1)}) \\\\\n",
    "o^{(t)} = f^\\sigma_o(x^{(t)},h^{(t-1)}) \\\\\n",
    "\\tilde{c}^{(t)} =  f^{tanh}_{\\tilde{c}}(x^{(t)},h^{(t-1)}) \\\\\n",
    "c^{(t)} =  f^{(t)}\\odot c^{(t-1)} + i^{(t)} \\odot \\tilde{c}^{(t)} \\\\\n",
    "y^{(t)} = h^{(t)} = o^{(t)} \\odot c^{(t)}\n",
    "$$\n",
    "\n",
    "シグモイド関数は、0～1の値をとり、どの程度の情報を流すかという割合を決定する意味でゲートの働きをする。\n",
    "\n",
    "* $ i $ input gate vector\n",
    "* $ o $ output gate vector \n",
    "* $ f $ forget gate vector\n",
    "* $ c $ context vector : 長期記憶用\n",
    "* $ h $ 短期記憶用\n",
    "\n",
    "### CEC\n",
    "\n",
    "CEC ( $ C^{t} $)は長期記憶のメモリで、この式は過去の情報と最新の情報をどの程度の割合で覚えさせるかを決定している。\n",
    "\n",
    "$$\n",
    "c^{(t)} =  f^{(t)}\\odot c^{(t-1)} + i^{(t)} \\odot \\tilde{c}^{(t)} \n",
    "$$\n",
    "\n",
    "#### 演習チャレンジ\n",
    "\n",
    "上記のように、入力に対し、入力ゲートの値をかけたものと、ひとつ前のセルに対し忘却ゲートをかけたものを足し合わせる必要があることから、\n",
    "\n",
    "(3）input_gate* a + forget_gate* c\n",
    "\n",
    "が正解\n",
    "\n",
    "### 覗き穴結合\n",
    "\n",
    "LSTM のバリエーションとして、CEC  から、出力ゲート、入力ゲートに「覗き穴結合」を行うものが存在する。\n",
    "入出力をCECの現在の値を反映させる目的であるが、あまり効果がなかった。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3.GRU (Gated Recurrent Unit)\n",
    " \n",
    " 従来のLSTMでは、パラメータが多数存在していたため、計算負荷が大きかった。しかし、GRUでは、そのパラメータを大幅に削減し、精度は同等またはそれ以上が望める様になった構造。\n",
    " \n",
    " <img src='GRU_1.jpg'>\n",
    " \n",
    "$$\n",
    "r(t)=W_r x(t) + U_r \\cdot h(t-1) + b_h(t) \\\\\n",
    "z(t) = W_z x(t) + U_z \\cdot h(t-1) + b_z(t) \\\\\n",
    "\\bar{h}(t) = f(W_r x(t) + U_r \\cdot (r(t) \\cdot h(t-1))) b_h (t)) \\\\\n",
    "h(t)=z(t) \\cdot h(t-1) + (1-z(t))\\cdot \\bar{h}(t)\n",
    "$$\n",
    " \n",
    "* r : どのくらい忘れるか\n",
    "* z : どのくらい更新するか\n",
    "\n",
    "を制御している\n",
    "\n",
    "\n",
    "\n",
    "やっぱりわかりにくいので別の図\n",
    "<img src='GRU_2.jpg'>\n",
    "$$\n",
    "z^{(t)} = f^\\sigma_z(x^{(t)},h^{(t-1)}) \\\\\n",
    "r^{(t)} = f^\\sigma_r(x^{(t)},h^{(t-1)}) \\\\\n",
    "\\tilde{h}^{(t)} =  f^{tanh}_{\\tilde{h}}(x^{(t)},r^{(t)} \\odot h^{(t-1)}) \\\\\n",
    "h^{(t)} = (1-z^{(t-1)})\\odot h^{(t-1)} + z^{(t)} \\odot \\tilde{h}^{(t)}\n",
    "$$\n",
    "* r : reset gate vector\n",
    "* z : update gate vector\n",
    "\n",
    " \n",
    " #### 確認テスト\n",
    " <b>LSTMとGRUの違い</b>\n",
    " \n",
    " GRU は LSTM と比較して、\n",
    " \n",
    " *  入力ゲート、出力ゲート、忘却ゲートがなくなり、リセットゲート、更新ゲートを追加\n",
    " * CECが存在しない\n",
    " \n",
    " #### 実習\n",
    " \n",
    " (3_3_predict_sin)\n",
    " \n",
    " <img src='RNN_2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4.双方向RNN\n",
    "  過去の情報だけでなく、未来の情報を加味することで、精度を向上させるためのモデル\n",
    "  <img src=\"BIDIRECTIONAL_1.jpg\">\n",
    "  \n",
    "  過去の情報 Sと未来の情報 S' をhidden state として保持する。\n",
    "  \n",
    "  \n",
    " \n",
    " #### 演習チャレンジ\n",
    "\n",
    "双方向RNNでは、順方向と逆方向の表現を時間方向に連結したものを記憶する必要があるので、\n",
    "<code>\n",
    "np.concatenate([h_f, h_b[::-1]], axis=1)\n",
    "</code>\n",
    "が正解\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5.Seq2Seq\n",
    " \n",
    " <img src=\"SEQ2SEQ_1.png\">\n",
    " \n",
    "* 機械対話や、機械翻訳などに使用されるモデル\n",
    "* Encoder-Decoderモデルの一種。RNNで構成されたエンコーダーとデコーダをつなぐ。\n",
    "* エンコーダーで文章を通すと、隠れ層には単語の意味がベクトル表現で保存される。one-hot ベクトルを意味ベクトル(embeded vector)に変換。単語の意味が似ている enbeded vector 表現でも距離が近い\n",
    "* デコーダーでは意味ベクトルのシーケンスから、単語列を生成する。\n",
    "* 単語/意味ベクトルの変換で異なる言語のものを用いることで翻訳が可能となる。\n",
    "\n",
    "#### 確認テスト\n",
    "3.seq2seq は encoder-decoderモデルの一種で機械翻訳等で用いられる。\n",
    "#### 演習チャレンジ\n",
    "単語を enbeding 表現に変換んする必要があるので、$ Ew $の計算が必要\n",
    "\n",
    "(1) E.dot(w)\n",
    "\n",
    "### HRED\n",
    "* 自動会話\n",
    "* 過去 n-1 個の会話から次の会話を生成する\n",
    "* 隠れ層を RNN 構造にすることにより、文脈を覚える Context RNN\n",
    "\n",
    "問題点\n",
    "* ありがちな答えしかださなくなる\n",
    "* 短い回答のみ\n",
    "\n",
    "\n",
    "### VHRED\n",
    "* HRED に VAE の潜在変数の概念を追加することで解決した構造\n",
    "\n",
    "### VAE\n",
    "* 潜在変数\n",
    "\n",
    "#### オートエンコーダー\n",
    "* 教師なし学習の一種\n",
    "* 入力画像を圧縮・伸縮（エンコード・デコード）を行った出力が、元の画像と同じになるようにする。\n",
    "*　次元削減が可能(潜在変数 Zで表す）\n",
    "### VAE\n",
    "* 通常のオートエンコーダーの場合、潜在変数 z に押し込めるが、zの構造がわからに\n",
    "* VAE では、z の正則化を行い、$ z \\sim N(0,1) $ の確率分布を仮定したもの。\n",
    "* 元データが近いものは、近いデータにエンコーディングされるようにしたい\n",
    "* VAE にノイズを加えることにより、汎用性の高い答えをだすことができる。\n",
    "\n",
    "#### 確認テスト\n",
    "VAE は潜在変数に確率分布を導入したもの\n",
    "\n",
    "#### 確認テスト\n",
    "\n",
    "* seq2seq とはある時系列データからある時系列データを生成するもの\n",
    "\n",
    "なので(2)が正解。\n",
    "\n",
    "尚、\n",
    "* HRED 文脈の意味を解釈しながら、時系列データを生成する\n",
    "* VHRED HREDを改良したもので、VAE を利用することにより、より自然な会話ができるように改良したもの\n",
    "\n",
    "#### 園主チャレンジ\n",
    "\n",
    "\n",
    "#### Seq2seqのコード確認\n",
    "\n",
    "lecture_chap1_exercise_public.ipynbから\n",
    "\n",
    "##### Encoder \n",
    " GRU を使って入力を意味ベクトルに変換\n",
    "\n",
    "<code>\n",
    "    def forward(self, seqs, input_lengths, hidden=None):\n",
    "        \"\"\"\n",
    "        :param seqs: tensor, 入力のバッチ, size=(max_length, batch_size)\n",
    "        :param input_lengths: 入力のバッチの各サンプルの文長\n",
    "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
    "        :return output: tensor, Encoderの出力, size=(max_length, batch_size, hidden_size)\n",
    "        :return hidden: tensor, Encoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        emb = self.embedding(seqs) # seqsはパディング済み\n",
    "        packed = pack_padded_sequence(emb, input_lengths) # PackedSequenceオブジェクトに変換\n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        return output, hidden\n",
    "</code>\n",
    "\n",
    "##### Decoder\n",
    " GRUを用いて、出力単語 $y_i$の確率分布を計算する。\n",
    " \n",
    " $$\n",
    " p(y_i)=p(y_i|y_{(i-1)}, S^{(d)}_i, C)\n",
    " $$\n",
    " \n",
    " $y_i$ 前の単語、$ S^{(d)}_i$隠れ状態、$C$意味ベクトル\n",
    " \n",
    "出力は $ P(y_i) $というｙ、単語の確率として出力される。\n",
    "\n",
    "\n",
    "<code>\n",
    "    def forward(self, seqs, hidden):\n",
    "        \"\"\"\n",
    "        :param seqs: tensor, 入力のバッチ, size=(1, batch_size)\n",
    "        :param hidden: tensor, 隠れ状態の初期値, Noneの場合は0で初期化される\n",
    "        :return output: tensor, Decoderの出力, size=(1, batch_size, output_size)\n",
    "        :return hidden: tensor, Decoderの隠れ状態, size=(1, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        emb = self.embedding(seqs)\n",
    "        output, hidden = self.gru(emb, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "</code>\n",
    "\n",
    "Encoder-Decoder をつなぐ\n",
    "\n",
    "<code>\n",
    "    def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n",
    "        \"\"\"\n",
    "        :param batch_X: tensor, 入力系列のバッチ, size=(max_length, batch_size)\n",
    "        :param lengths_X: list, 入力系列のバッチ内の各サンプルの文長\n",
    "        :param max_length: int, Decoderの最大文長\n",
    "        :param batch_Y: tensor, Decoderで用いるターゲット系列\n",
    "        :param use_teacher_forcing: Decoderでターゲット系列を入力とするフラグ\n",
    "        :return decoder_outputs: tensor, Decoderの出力, \n",
    "            size=(max_length, batch_size, self.decoder.output_size)\n",
    "        \"\"\"\n",
    "        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n",
    "        # decoderの入力と隠れ層の初期状態を定義\n",
    "        decoder_input = torch.tensor([BOS] * self.beam_size, dtype=torch.long, device=device)\n",
    "        decoder_input = decoder_input.unsqueeze(0)  # (1, batch_size)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        # beam_sizeの数だけrepeatする\n",
    "        decoder_input = decoder_input.expand(1, beam_size)\n",
    "        decoder_hidden = decoder_hidden.expand(1, beam_size, -1).contiguous()\n",
    "        # decoderの出力のホルダーを定義\n",
    "        decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device) # max_length分の固定長\n",
    "        # 各時刻ごとに処理\n",
    "        for t in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[t] = decoder_output\n",
    "            # 次の時刻のdecoderの入力を決定\n",
    "            if use_teacher_forcing and batch_Y is not None:  # teacher forceの場合、ターゲット系列を用いる\n",
    "                decoder_input = batch_Y[t].unsqueeze(0)\n",
    "            else:  # teacher forceでない場合、自身の出力を用いる\n",
    "                decoder_input = decoder_output.max(-1)[1]\n",
    "        return decoder_outputs\n",
    "</code>\n",
    "\n",
    "ここでは、decoder_output.max(-1)[1]で最も確率の高い単語を単純に選んでいるが、実際の単語を選択する際には Beam Search という手法をとる。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6.Word2vec\n",
    " \n",
    " 単語のベクトル表現を行う場合、one-hot ベクトル表現をそのまま使うと、データ量が巨大になる（単語数分の要素が必要）\n",
    " \n",
    " $$\n",
    " 'apple' \\rightarrow [0,0,\\dots, 1, 0, \\dots ] \\\\\n",
    "  'pear' \\rightarrow [0,0,\\dots, 0, 1, \\dots ]\n",
    " $$\n",
    " \n",
    " \n",
    "そこで、one-hotベクトル表現で表現されているベクトルを、低次元の空間にマッピングし、\n",
    "また、意味的に近い単語を近い位置になるような変換を行うのが word2vec\n",
    " \n",
    "この変換行列は COW または skip-gram という学習を行わせることで\n",
    "間接的に取得することができる。\n",
    "\n",
    "### COW \n",
    "前後の単語列から、中央の単語を予測するモデル\n",
    "\n",
    "### skip-gram\n",
    "一つの単語から、前後の単語を推測するモデル\n",
    "\n",
    "COW 等を学習させると、意味ベクトルから元のワンホットベクトル表現への変換行列を得ることが\n",
    "できるが、これがまさに単語の辞書に相当する\n",
    "\n",
    "### ベクトル表現\n",
    "\n",
    "word2vec によって単語のベクトル表現を行うことにより、\n",
    "$$\n",
    "'King' - 'man' + 'woman' = 'Queen'\n",
    "$$\n",
    "等といった、単語の意味的な演算を行うことが可能となる。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7.Attention Mechanism\n",
    " \n",
    " 入力と出力のどの単語が関連しているのかの関連度を学習する仕組み。\n",
    " \n",
    "1文の中で重要な単語を自力で見つけられるようにする仕組みとなる。\n",
    "\n",
    "現在では様々なネットワークで利用される。\n",
    "\n",
    "* Transformer\n",
    "* BERT\n",
    "* GPT-3\n",
    "\n",
    "等でも使われている。\n",
    "\n",
    "機械翻訳で使われている\n",
    "\n",
    "Encoder-Decoder の限界\n",
    "\n",
    "ベクトルのサイズが固定で、扱える情報の量や複雑さに制限\n",
    "\n",
    "Encoder 部分は GRU\n",
    "\n",
    "単語を意味ベクトルに変換\n",
    "\n",
    "Decoder\n",
    "$$\n",
    "P(y_i)=p(y_i|y_{i-1}, S^{(d)}_i, C)\n",
    "$$\n",
    "\n",
    "* $ y_i $ : i番目の単語\n",
    "* $ s^{(d)}_i $: 隠れ状態\n",
    "* $ c $ : 意味ベクトル\n",
    "\n",
    "\n",
    "### 確認テスト \n",
    "* RNN：時系列データを処理するのに適したネットワーク\n",
    "* Word2Vec：単語の分散表現を得る手法\n",
    "* seq2seq：一つの時系列データから別の時系列データを得るネットワーク\n",
    "* Attention：時系列データの中身に対して関連性の重みをつける手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8.強化学習\n",
    " 長期的に報酬を最大化できるように環境のなかで行動を選択できるエージェントを作ることを目標とする機械学習の一分野\n",
    " \n",
    "行動の結果として与えられる利益(報酬)をもとに、行動を決定する原理を改善していく仕組み\n",
    " \n",
    " <img src=\"REINFORCEMENT_1.jpg\">\n",
    " \n",
    "### 方策\n",
    "ある状態において行える行動の中から何を選ぶかの確率を表したもの。\n",
    "\n",
    "状態sにおいて、行動aを起こした時の方策\n",
    "$$\n",
    "\\pi_t(a|s)\n",
    "$$\n",
    "\n",
    "### 報酬\n",
    "\n",
    "ある行動をとった時に得られるもの\n",
    "\n",
    "$$\n",
    "R_t\n",
    "$$\n",
    "\n",
    "### 収益\n",
    "\n",
    "ある時点からみて、最後までやり通した時の報酬の合計\n",
    "\n",
    "過去の収益に対しては割引率 $ \\gamma $ がかかり、\n",
    "\n",
    "$$\n",
    "G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+2} + \\dots + = \\sum_k^\\infty \\gamma^k R_{r+t+1}\n",
    "$$\n",
    "\n",
    "### 状態価値関数\n",
    "状態 s において、方策 $ \\pi $ に従った時の期待収益\n",
    "\n",
    "$$\n",
    "V^\\pi(s) = \\mathbf{E}_\\pi [G_t|S_t=s]\n",
    "$$\n",
    "\n",
    "\n",
    "### 行動価値関数\n",
    "ある状態 s において行動 a をとり、その後方策$\\pi$従った場合の期待収益\n",
    "\n",
    "$$\n",
    "Q^\\pi(s,a) = \\mathbf{E}_\\pi [G_t|S_t=s, A_t=a]\n",
    "$$\n",
    "\n",
    "すなわち、\n",
    "$$\n",
    "V^\\pi(s) = \\sum_\\pi \\pi(a|s)Q^\\pi(s,a)\n",
    "$$\n",
    "\n",
    "\n",
    "### 強化学習の手法\n",
    "\n",
    "方策ベースと価値ベース\n",
    "\n",
    "*方策ベース：明示的な方策があり、現在の方策を改善する\n",
    "*価値ベース：明示的な方策はなく、サンプルから学習し、最適な価値関数の値を逐次推定する\n",
    "\n",
    "\n",
    "\n",
    "#### 動的計画法\n",
    "環境の完全なモデルがマルコフ決定勝てとして与えられている時に提供できるモデル。\n",
    "\n",
    "#### モンテカルロ法\n",
    "遷移のサンプルを取得し、与えられた収益を平均化することによって行動価値を推定\n",
    "価値関数や方策の改善は、一連の行動（エピソード）終了後に行う。\n",
    "\n",
    "#### TD学習\n",
    "目標の価値と現在の価値のずれを修正することによって、価値関数を推定する。\n",
    "\n",
    "Sarsa と Q 学習がある。\n",
    "\n",
    "Sarsa\n",
    "$$\n",
    "Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha [R_{(t+1)} + \\gamma Q(S_{(t+1)}, A_{(t+1)}) - Q(S_t, A_t)] \n",
    "$$\n",
    "\n",
    "Q学習\n",
    "$$\n",
    "Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha [R_{(t+1)} + \\gamma \\max_\\alpha Q(S_{(t+1)},\\alpha) - Q(S_t, A_t)] \n",
    "$$\n",
    "\n",
    "#### 方策勾配法\n",
    "方策$ \\pi $がパラメタ$\\theta$をつかって\n",
    "$$\n",
    "\\pi(a|s,\\theta)\n",
    "$$\n",
    "であらわされるとする。この時、勾配法により最適な$\\theta$を求める。\n",
    "$$\n",
    "\\theta^{(t+1)} = \\theta^{(t)}+\\eta \\nabla J(\\theta)\n",
    "$$\n",
    "方策勾配定理により、\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta)=\\mathbf{E}_{\\pi_\\alpha}[(\\nabla_\\theta \\log \\pi_\\theta(a|s)Q^\\pi(s,a))]\n",
    "$$\n",
    "が成り立つ。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 9.AlpahaGO\n",
    " \n",
    " 強化学習を利用した碁の囲碁プログラム\n",
    " \n",
    " 現在、\n",
    " \n",
    " * AlphagoGO Lee\n",
    " * AlphaGO ZERO\n",
    " \n",
    " の2種類がある。\n",
    " \n",
    " ### AlphaGO Lee\n",
    " \n",
    "方策関数を表現するPolicyNetと価値関数を表現するValueNet \n",
    "の2つのネットワークがあり、\n",
    "二つとも畳み込みネットワークで構成さえれる。\n",
    "\n",
    "PolicyNet は 19x19 マスの着手予想確率が出力され、\n",
    "ValueNet は現局面の勝率が 1 ～　-1で出力される。\n",
    "\n",
    "\n",
    "学習は、\n",
    "\n",
    "1. 教師あり学習によるRollOutPolicyとPolicyNetの学習\n",
    "2. 強化学習によるPolicyNetの学習\n",
    "3. 強化学習によるValueNetの学習\n",
    "\n",
    "のステップで行われる。\n",
    "\n",
    "1. 教師あり学習によるRollOutPolicyとPolicyNetの学習\n",
    "\n",
    "KGS Go Server（ネット囲碁対局サイト）の棋譜データから3000万局面分の教師を用意し、教師と同じ着手を予測できるよう学習を行った。\n",
    "\n",
    "2. 強化学習によるPolicyNetの学習\n",
    "\n",
    "現状のPolicyNetとPolicyPoolからランダムに選択されたPolicyNetと対局シミュレーションを行い、その結果を用いて方策勾配法で学習を行った。\n",
    "\n",
    "3. 強化学習によるValueNetの学習\n",
    "\n",
    "PolicyNetを使用して対局シミュレーションを行い、その結果の勝敗を教師として学習した。\n",
    "\n",
    "\n",
    "### AlphaGO ZERO\n",
    "\n",
    "\n",
    "AlphaGo(Lee) との違い\n",
    "\n",
    "* 教師あり学習を一切行わず、強化学習のみで作成\n",
    "* 特徴入力からヒューリスティックな要素を排除し、石の配置のみにした\n",
    "* PolicyNetとValueNetを１つのネットワークに統合した\n",
    "* Residual Netを導入した\n",
    "* モンテカルロ木探索からRollOutシミュレーションをなくした\n",
    "\n",
    "\n",
    "#### ResidualNetwork\n",
    "\n",
    "ネットワークにショートカットを設ける\n",
    "勾配消失問題、勾配爆発を避ける\n",
    "\n",
    "また、\n",
    "アンサンブル効果が期待できる\n",
    "\n",
    "100層を超えるネットワークでも安定するようになった。（AlphaGO ZERO では ResidualBlock が39回）\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.軽量化・高速化技術\n",
    " \n",
    "深層学習は多くのデータを使用したり、パラメータ調整のために多くの時間を使用したりするため、高速な計算が求められる\n",
    "そのため、以下のような高速、軽量化の手法が用いられる。\n",
    "\n",
    "### 分散深層学習\n",
    " * データ並列化：データを分割し、複数のワーカーで計算を行う。\n",
    " * モデル並列化：モデルを各ワーカに分割し、それぞれのモデルで計算させる\n",
    " 縦方向、横方向に分割\n",
    " \n",
    "### GPUによる高速化\n",
    " * GPGPUの利用\n",
    " \n",
    " * CPU\n",
    "高性能なコアが少数\n",
    "\n",
    "複雑で連続的な処理が得意\n",
    " * GPU\n",
    " 低性能なコアが多数。簡単な並列処理が得意\n",
    " \n",
    " GPUを使うためのフレームワークは主に2種類。ただし、 ほとんど CUDAでの実装 \n",
    " * CUDA\n",
    " * OpenCL\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "### モデルの軽量化\n",
    " * 量子化　: 64bitの浮動小数を 32bit に精度を落とす等\n",
    " * 蒸留　：規模の大きなモデルの知識を使い軽量なモデルの作成を行う。\n",
    "教師モデル、生徒モデルを作成\n",
    "\n",
    " * プルーニング　：　モデルの精度に寄与が少ないニューロンを削減する\n",
    " 重みが小さいところを削除する\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 11.応用モデル\n",
    " \n",
    " ### mobilenet\n",
    "\n",
    "畳み込みを工夫\n",
    "\n",
    "Depthwise ConvolutionとPointwise Convolutionの組み合わせで軽量化を実現\n",
    "\n",
    "#### Depthwise\n",
    "\n",
    "一枚のフィルタで全チャンネルの畳み込みを行う。\n",
    "\n",
    "計算量\n",
    "* 一般的な畳み込みの計算量 : H x W x K x K x C x M\n",
    "* DepthWize  : H x W x K x K x C\n",
    "\n",
    "\n",
    "#### PointWise\n",
    "\n",
    "畳み込みをdepthwise, pointwise に分離\n",
    "1X1　のフィルタを用いる\n",
    "\n",
    "計算量 H x W x C x M\n",
    "\n",
    "### densenet\n",
    "画像認識ネットワーク\n",
    "\n",
    "### DenseNet\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "* レイヤー間を流れるデータの分布を、ミニバッチ単位で平均が0・分散が1になるように正規化する。\n",
    "* Batch Normalizationはニューラルネットワークにおいて学習時間の短縮や初期値への依存低減、過学習の抑制など効果がある\n",
    "\n",
    "\n",
    "### Wavenet\n",
    "\n",
    "* 生の音声波形を生成するモデル\n",
    "\n",
    "*　時系列データに対して畳み込み　（Dilated Convolution)を適用する。\n",
    "\n",
    "*層が深くなるにつれて畳み込むリンクを離す\n",
    "*受容野を簡単に増やすことができる\n",
    "\n",
    "<img src='DILATED_1.jpg'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 12.Transformer\n",
    "  Attention 機構のみを使った計算量の少ないモデル。\n",
    "\n",
    "### Encoder / Decoder モデルの問題点\n",
    " seq2seq 等、Encoder / Decoer を使ったモデルでは、固定長ベクトルを使うため、長い文章でのスコアがよくなかった。\n",
    "\n",
    " ### Attention\n",
    "\n",
    " 翻訳先の各単語を選択する際に、翻訳元の文中の各単語の隠れ状態を利用\n",
    " \n",
    "\n",
    "\n",
    "翻訳元の各単語の隠れ状態を利用する。\n",
    "\n",
    "$$\n",
    "p(y_i) = p(y_i|p_{i-1}, S^{(d)}_i, C_i) \\\\\n",
    "C_i = \\sum_j \\alpha_{ij} h_j \\\\\n",
    "\\alpha_{ij} = {exp(e_ij) \\over \\sum_k exp(e_{ik})}\n",
    "$$\n",
    "$ C_i $は Attention で $h_j$の重み付き和。$\\alpha_i$の総和は1\n",
    "\n",
    "\n",
    "Attention は query(検索クエリ)に一致するkeyを索引し、対応するvalueを取り出す操作と解釈できる。\n",
    "\n",
    " $$\n",
    " \\sigma(Q, \\mathbf{K}) = V\n",
    " $$\n",
    " \n",
    " 元々機械翻訳で出てきたアルゴリズムであるが、多くのモデル（画像認識の ViT等)に適用されている。\n",
    " \n",
    " \n",
    " \n",
    " ### Transformerの構造\n",
    "  \n",
    " <img src='TRANSFORMER_1.jpg'>\n",
    " \n",
    "* RNN を使用していないため、軽い\n",
    "* BERT, GPT-3 等にもTransfomer の技術が利用されている。\n",
    " \n",
    " \n",
    " \n",
    "4  つの主要なモジュールからなる。\n",
    "\n",
    "- Positional Encoding: 入出力の単語のEmbedding時に単語の位置情報を埋め込む\n",
    "- Scaled Dot-Product Attention: 内積でAttentionを計算し、スケーリングを行う\n",
    "- Multi-head Attention: Scaled Dot-Product Attentionを複数のヘッドで並列化する\n",
    "- Position-Wise Feed Forward Network: 単語列の位置ごとに独立して処理を行う\n",
    "\n",
    "### Position Encoding\n",
    "\n",
    "TransformerはRNNを使用しておらず、単語順序を考慮することができないので、\n",
    "入力データに位置情報を埋め込むPositional Encodingを加算する。\n",
    "\n",
    "\n",
    "$$\n",
    "PE_{(pos, 2i)} = \\sin(pos/10000^{2i/d_{model}}) \\\\\n",
    "PE_{(pos, 2i+1)} = \\cos(pos/10000^{2i/d_{model}})\n",
    "$$\n",
    "\n",
    "$pos$は単語の位置、$i$は成分の次元\n",
    "\n",
    "\n",
    "<code>\n",
    "def position_encoding_init(n_position, d_pos_vec):\n",
    "    \"\"\"\n",
    "    Positional Encodingのための行列の初期化を行う\n",
    "    :param n_position: int, 系列長\n",
    "    :param d_pos_vec: int, 隠れ層の次元数\n",
    "    :return torch.tensor, size=(n_position, d_pos_vec)\n",
    "    \"\"\"\n",
    "    # PADがある単語の位置はpos=0にしておき、position_encも0にする\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2 * (j // 2) / d_pos_vec) for j in range(d_pos_vec)]\n",
    "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2])  # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2])  # dim 2i+1\n",
    "    return torch.tensor(position_enc, dtype=torch.float)\n",
    "</code>\n",
    "\n",
    "\n",
    "### Scaled Dot-Product Attention\n",
    "\n",
    "Attention には\n",
    "* Additive Attention\n",
    "* Dot-Product Attention\n",
    "の2種類が存在するが、Dot-Product Attention の方がパラメタが少なく高速。Transformer で採用\n",
    "\n",
    "Transfomer では、ベクトルの次元数、$d_k$が大きく言時、ない席が大きくなりすぎ、Softmax の勾配が極端に小さくなることを伏せくため、query($Q$)とkey($K$)の内積をスケーリング因子 $\\sqrt{d_k}$ で除算する。\n",
    "\n",
    "$$\n",
    "Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "$$ \n",
    "\n",
    "### Multi-head Attention\n",
    "\n",
    "TransformerではAttentionを複数のヘッドで並列に行うMulti-Head Attentionを使用している。\n",
    "\n",
    "複数のヘッドでAttentionを行うことにより、各ヘッドが異なる部分空間を処理でき、精度が向上する\n",
    "\n",
    "\n",
    "### Position-wise Feed-Forward Networks\n",
    "\n",
    "$$\n",
    "FFN(x)=max(0,xW1,b1)W2+b2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 補）評価指標\n",
    "\n",
    "機械翻訳の精度の指標として BLEU がよく使われる。\n",
    "\n",
    "BLEUは\n",
    " $$\n",
    " BLEU=\\exp(min(0, 1 - \\frac{r}{c}))\\exp (\\sum w_n \\log P_n)\n",
    " $$\n",
    "と定義される。\n",
    "\n",
    "$P_n$はn-gramにおけるPrecisionで\n",
    " $$\n",
    "Precision = { 参考訳に含まれる単語数 \\over 提案訳文の単語数 }\n",
    " $$\n",
    "と定義される。ただし、参考訳で現れる単語は一回のみ\n",
    "\n",
    " $$\n",
    "\\exp (\\sum w_n \\log P_n)\n",
    " $$\n",
    "は 1～Nグラムまでの相乗平均をとることを意味する。\n",
    "\n",
    "$ min(0, 1 - \\frac{r}{c})$\n",
    "は短い文におけるペナルティ(Brevity Penalty)で、\n",
    "極端に短い文の方が上記で定義されるPrecisiohnが大きくなることへのペナルティである。\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 13.物体検知・セグメンテーション\n",
    " \n",
    "物体検知では、入力画像に対して、どこに何を見つけたかを出力する。\n",
    "出力項目としては、以下\n",
    "* Bounding Box\n",
    "* ラベル\n",
    "* コンフィデンス\n",
    "\n",
    "代表的なデータセットとして以下のものがある。\n",
    "* VOC12\n",
    "* ILSVRC17\n",
    "* MS COCO18\n",
    "* OICOD18\n",
    "等\n",
    "\n",
    "データ量が大きいだけではだめで、目的に合わせて選択する必要がある。\n",
    "\n",
    "* クラス数\n",
    "* 訓練データ＋テストデータ数\n",
    "* BOX/画像\n",
    "\n",
    "等\n",
    "\n",
    " \n",
    " \n",
    "### 物体検知の評価指標\n",
    "\n",
    "\n",
    "Accuracy だけでは、ダメ。\n",
    "\n",
    "$$\n",
    "Precision = { TP \\over TP + FP}\n",
    "$$\n",
    "$$\n",
    "Recall = {TP \\over TP + FN}\n",
    "$$\n",
    "\n",
    "Recall =\n",
    "クラスラベルだけでなく, 物体位置の予測精度も評価したい！クラスラベルだけでなく, 物体位置の予測精度も評価したい！\n",
    "\n",
    "$$\n",
    "IoU={TP \\over TP+FP+FN}={Area\\ of\\ Overlap \\over Area\\ of\\ Union}\n",
    "$$\n",
    "\n",
    "AP (Average Precision)\n",
    "\n",
    "$$\n",
    "AP = \\int^1_0 P(R)dR\n",
    "$$\n",
    "PR曲線の下側の面積\n",
    "\n",
    "クラス毎に計算。\n",
    "\n",
    "$$\n",
    "mAP = \\frac{1}{C}\\sum_C AP_c\n",
    "$$\n",
    "\n",
    "全クラスでの平均\n",
    "\n",
    "\n",
    "SHFT から DCNN\n",
    "\n",
    "代表的なネットワーク\n",
    "\n",
    "|  年  |  ネットワーク  |\n",
    "| ---- | ---- |\n",
    "|  2012  |  AlexNet  |\n",
    "|  2014  |  VGGNet, GoogLeNet  |\n",
    "|  2015|  ResNet  |\n",
    "|  2016|  DenseNet、Inception-ResNet  |\n",
    "|  2017|  MobileNet  |\n",
    "| 2018 | AmoebaNet |\n",
    "\n",
    "代表的な物体検知フレームワーク\n",
    "\n",
    "|  年  |  ネットワーク  |\n",
    "| ---- | ---- |\n",
    "|  2012  |  DCNN  |\n",
    "|  2013  |  DecoNet, RCNN  |\n",
    "|  2014  |  SPPNet  |\n",
    "|  2015  |  Fast RCNN、Faster RCNN、YOLO、SSD  |\n",
    "|  2016  |  RFCN、YOLO9000、FPN  |\n",
    "|  2017  |  RetinaNet、Mask RCNN |\n",
    "|  2018  |  CornerNet |\n",
    "\n",
    "\n",
    "慮域の検出と、クラス判別を2段階で行うか、同時に行うかで\n",
    "\n",
    "2段階検出/ 1段階検出\n",
    "\n",
    "に分けられる。\n",
    "\n",
    "### SSD (Single Shot Detector)\n",
    "\n",
    "* DefaultBOX を用意：学習が進む毎に変形\n",
    "\n",
    "1つの特徴量に対して複数の DefaultBOX を置く\n",
    "\n",
    "\n",
    "マルチスケール特徴マップ\n",
    "\n",
    "### Semantic Segmentation\n",
    "\n",
    "各ピクセルに対してクラスを決定する。\n",
    "\n",
    "ところが、\n",
    "Covolution と Pooling を繰り返すことにより、解像度が落ちることが問題となる。→アップサンプリングが必要\n",
    "\n",
    "Pooling の必要性→受容野を広げる\n",
    "\n",
    "#### Decomvolution\n",
    "\n",
    "<img src=\"DECONVOLUTION_1.jpg\">\n",
    "\n",
    "#### Unpooling\n",
    "場所情報を Switch Variable として覚えておく\n",
    "\n",
    "#### Up-Sampling\n",
    "\n",
    "Poolingにより輪郭情報が失われ行く。\n",
    "低レイヤーPooling層の出力をelement-wise addition することでローカルな情報を補完してからUp-samplin\n",
    "\n",
    "#### Dilated Convolution\n",
    "\n",
    "Covolution の段階で受容野を広げる\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
