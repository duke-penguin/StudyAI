{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ラビットチャレンジ　応用数学\n",
    "## 1. 線形代数\n",
    "\n",
    "### 固有値・固有ベクトル\n",
    "$ n \\times n $の正方行列 $ A $ に対して、\n",
    "$$ A x = \\lambda \\vec{x} $$\n",
    "を満たす x を固有ベクトル。$ \\lambda  $ を固有値と呼ぶ。\n",
    "\n",
    "この時の $ \\lambda_1, \\lambda_2, \\dots \\lambda_n $　に対して\n",
    "$\\vec{x_1}, \\vec{x_2}, \\dots \\vec{x_n} $ が決まり、\n",
    "$$ \n",
    "V = [ \\vec{x_1}, \\vec{x_2} \\dots \\vec{x_n} ]\n",
    "$$\n",
    "という行列用いると、\n",
    "\n",
    "$$\n",
    "\\Lambda = V^{-1}AV = \\begin{bmatrix}\n",
    "  \\lambda_1 &         0 &  \\dots &         0 \\\\\n",
    "          0 & \\lambda_2 &  \\dots &         0 \\\\\n",
    "     \\vdots &    \\vdots & \\ddots &    \\vdots \\\\\n",
    "          0 &         0 &  \\dots & \\lambda_n\n",
    "\\end{bmatrix}          \n",
    "$$\n",
    "のように対角化することができる。この $ \\Lambda $ を用いて正方行列 A を\n",
    "$$\n",
    "A = V \\Lambda V^{-1}\n",
    "$$\n",
    "のように分解することを固有値分解と呼ぶ。\n",
    "\n",
    "### 特異値・特異値分解\n",
    "固有値分解は一般の行列に拡張することができ、$ m \\times n $、階数 $ r $の行列 $ M $に対して\n",
    "$$\n",
    "M = USV ^{-1}\n",
    "$$\n",
    "のように分解できる。ただし、U は $ m \\times m $ の直行行列、 $ V $ は $ n \\times n $ の直行行列、$S $は $ m \\times n $ の行列で、\n",
    "$$\n",
    "S  = \\begin{bmatrix}\n",
    "  \\sigma_1 &         0 &  \\dots &         0  & 0 \\\\\n",
    "          0 & \\sigma_2 &  \\dots &         0  & 0 \\\\\n",
    "     \\vdots &    \\vdots & \\ddots &    \\vdots & 0 \\\\\n",
    "          0 &         0 &  \\dots & \\sigma_r & 0 \\\\\n",
    "          0 & 0 & 0 & 0 & 0\n",
    "\\end{bmatrix}          \n",
    "$$\n",
    "のような対角成分の一部のみ非ゼロの行列である。\n",
    "\n",
    "このような分解を特異値分解と呼び、$ \\sigma_1, \\sigma_2 \\dots \\sigma_r $を特異値と呼ぶ\n",
    "\n",
    "特異値分解は画像の圧縮等に応用することができる。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.統計\n",
    "### ベイズの定理\n",
    "事象 A, B に対して\n",
    "\n",
    "\n",
    "条件付き確率\n",
    "$$\n",
    "P(A\\mid B) = \\frac{P(A\\cap B)} {P(B)}\n",
    "$$\n",
    "\n",
    "はBが真であるときAが発生する確率で、Bが与えられたときの事後確率と呼ぶ。\n",
    "A,Bが独立の時、\n",
    "\n",
    "$$\n",
    "P(A\\mid B) = P(A) P(B)\n",
    "$$\n",
    "\n",
    "が成立する。\n",
    "\n",
    "一般に、ベイズ則\n",
    "$$\n",
    "P(A\\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}\n",
    "$$\n",
    "が成立する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計量\n",
    "\n",
    "事象 $ x_i $に対して確率変数 $ f(x_i) $その確率が $ P(x_i) $の時\n",
    "\n",
    "平均は\n",
    "$$\n",
    "E(f) = \\sum{ f(x_i) P(x_i)}\n",
    "$$\n",
    "となる。連続関数の場合\n",
    "$$\n",
    "E(f) = \\int{f(x) P(x) dx}\n",
    "$$\n",
    "となる。\n",
    "\n",
    "また、分散は\n",
    "$$\n",
    "Var(f) = E((f - E_f)^2) = E(f^2) - E(f)^2\n",
    "$$\n",
    "となり、これはデータの散らばり具合を表す。\n",
    "\n",
    "一方、確率変数fとgの共分散は\n",
    "$$\n",
    "Var(f) = E((f - E_f)(g-E_g))\n",
    "$$\n",
    "\n",
    "となる。共分散は2つのデータの傾向の違いを表し、2つのデータに関連性がなければ0になる。\n",
    "\n",
    "### 代表的な分布\n",
    "\n",
    "\n",
    "#### 二項分布\n",
    "分布関数\n",
    "$$\n",
    "P(X=k) = {}_n C_k p^k (1-p)^{n-k}\n",
    "$$\n",
    "平均\n",
    "$$\n",
    "E(X) = n p\n",
    "$$\n",
    "分散\n",
    "$$\n",
    "V(X) = np(1-p)\n",
    "$$\n",
    "\n",
    "#### ポアソン分布\n",
    "分布関数\n",
    "$$\n",
    "P(X=k) = { e^{-\\lambda} \\lambda^k \\over k ! }\n",
    "$$\n",
    "平均\n",
    "$$\n",
    "E(X) = \\lambda\n",
    "$$\n",
    "\n",
    "$$分散\n",
    "V(X) = \\lambda\n",
    "$$\n",
    "\n",
    "#### 幾何分布\n",
    "分布関数\n",
    "$$\n",
    "P(X=k)=(1-p)^{k-1}p\n",
    "$$\n",
    "平均\n",
    "$$\n",
    "E(X) = \\frac{1}{p}\n",
    "$$\n",
    "分散\n",
    "$$\n",
    "V(X) =  \\frac{1-p}{p^2}\n",
    "$$\n",
    "\n",
    "#### 正規分布\n",
    "分布関数\n",
    "$$\n",
    "f(x) = {1 \\over { \\sqrt{2 \\pi} \\sigma}} e ^ {-{(x-\\mu)^2 \\over {2 \\sigma ^2}}}\n",
    "$$\n",
    "平均\n",
    "$$\n",
    "E(X) = \\mu\n",
    "$$\n",
    "分散\n",
    "$$\n",
    "V(X) = \\sigma ^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.情報理論\n",
    "### エントロピー\n",
    "\n",
    "エントロピーは情報量を表し、ある出来事が起こった場合、それがどれだけ起こりにくいかを表す指標\n",
    "ある事象 xが起こる確率を $ P(x) $とすると、自己情報量 $I(x)$は\n",
    "$$\n",
    "I(x) = - \\log_2(P(x))\n",
    "$$\n",
    "であらわされる。\n",
    "\n",
    "### 平均情報量\n",
    "シャノンエントロピーは情報量の期待値で、\n",
    "$$\n",
    "H(x) = E(I(x))\n",
    "$$\n",
    "で定義される。\n",
    "\n",
    "### カルバック・ライブラーダイバージェンス\n",
    "2つの分布 P(x)とQ(x)がどれだけ異なるかという指標として、以下で定義される\n",
    "カルバック・ライブラーダイバージェンスが用いられる。\n",
    "\n",
    "\n",
    "$$\n",
    "D_{\\mathrm{KL}}(P\\|Q) =\\sum_x P(x) \\log \\frac{P(i)}{Q(i)}\n",
    "$$\n",
    "\n",
    "### 交差エントロピー\n",
    "\n",
    "カルバック・ライブラーダイバージェンスの一文を取り出したもので、\n",
    "Q についての自己情報量をPの分布で平均したもの。\n",
    "\n",
    "$$\n",
    "H(P,Q) = -\\sum_x P(x) \\log Q(x)\n",
    "$$\n",
    "\n",
    "機械学習により得られた分布 Q が真の分布 P がどのくらい離れているかという\n",
    "指標。損失関数として用いられる。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
